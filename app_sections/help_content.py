"""
Sistema de ayuda contextual para todas las funciones de la aplicaci√≥n.

Cada funci√≥n tiene 3 componentes de ayuda:
1. Fundamento te√≥rico SEO
2. C√≥mo interpretar resultados
3. Mejores pr√°cticas de uso
"""

from __future__ import annotations

from typing import Dict, TypedDict


class HelpContent(TypedDict):
    """Estructura de contenido de ayuda para cada funci√≥n."""
    title: str
    seo_theory: str
    interpretation: str
    best_practices: str


# Diccionario centralizado con toda la ayuda
HELP_SECTIONS: Dict[str, HelpContent] = {
    "clustering": {
        "title": "Clustering de Contenido",
        "seo_theory": (
            "El clustering sem√°ntico agrupa URLs con contenido similar bas√°ndose en la proximidad "
            "vectorial de sus embeddings. En SEO, esto permite identificar canibalizaci√≥n de keywords "
            "(m√∫ltiples p√°ginas compitiendo por la misma intenci√≥n de b√∫squeda), detectar gaps de "
            "contenido (temas relacionados sin cobertura) y optimizar la arquitectura de informaci√≥n. "
            "Los motores de b√∫squeda modernos como Google usan embeddings similares (BERT, MUM) para "
            "entender la similitud sem√°ntica entre documentos, por lo que agrupar tu contenido de forma "
            "coherente mejora la relevancia tem√°tica y la autoridad topical."
        ),
        "interpretation": (
            "Cada cluster representa un tema o intenci√≥n de b√∫squeda. URLs en el mismo cluster tienen "
            "contenido muy similar y probablemente compiten entre s√≠. Un **cluster grande** (muchas URLs) "
            "puede indicar canibalizaci√≥n de keywords. **Clusters peque√±os** (2-3 URLs) pueden ser "
            "oportunidades para consolidar contenido. El **Silhouette Score** (0-1) mide la calidad: "
            "valores >0.5 indican clusters bien definidos, <0.3 sugieren solapamiento. URLs con etiqueta "
            "'noise' (-1) son outliers sin tema claro. El **n√∫mero √≥ptimo de clusters** (k) se detecta "
            "autom√°ticamente buscando el m√°ximo Silhouette Score."
        ),
        "best_practices": (
            "**Paso 1**: Carga un CSV con columna de URL y embeddings pre-calculados. **Paso 2**: Usa "
            "detecci√≥n autom√°tica de k para encontrar el n√∫mero √≥ptimo de grupos. **Paso 3**: Revisa "
            "clusters grandes (>10 URLs) para identificar canibalizaci√≥n - considera consolidar contenido "
            "similar en una p√°gina autoritativa. **Paso 4**: Examina 'noise' URLs - pueden necesitar "
            "reescritura para enfocarse en un tema claro. **Paso 5**: Exporta resultados y √∫salos para "
            "planificar internal linking estrat√©gico (enlaza dentro de cada cluster y entre clusters "
            "relacionados). Ideal para auditor√≠as de contenido y planificaci√≥n de arquitectura de informaci√≥n."
        ),
    },
    "knowledge_graph": {
        "title": "An√°lisis de Grafo de Conocimiento",
        "seo_theory": (
            "Los Knowledge Graphs son fundamentales en SEO moderno. Google utiliza su Knowledge Graph para "
            "conectar entidades (personas, lugares, conceptos) y entender las relaciones entre ellas. Cuando "
            "tu contenido menciona entidades de forma coherente y frecuente, se beneficia del 'Quality Smear' "
            "(Patente US9183499B1): la calidad de entidades relacionadas se propaga entre s√≠. Un contenido que "
            "co-ocurre sistem√°ticamente con entidades de alta autoridad se√±ala profundidad tem√°tica. El an√°lisis "
            "NER (Named Entity Recognition) + Entity Linking a Wikidata te permite mapear tu contenido al mismo "
            "Knowledge Graph que usa Google, identificando gaps de entidades y optimizando la cobertura sem√°ntica."
        ),
        "interpretation": (
            "El grafo visualiza entidades (nodos) y sus relaciones (aristas). El **tama√±o del nodo** representa "
            "la autoridad t√≥pica (prominence + centralidad). **Nodos centrales** con muchas conexiones son "
            "conceptos clave de tu contenido. **Relaciones SPO** (Sujeto-Predicado-Objeto) muestran c√≥mo se "
            "conectan las entidades. La **tabla de entidades** muestra: (1) Frecuencia consolidada = menciones "
            "totales, (2) Prominence sint√°ctica = importancia gramatical (sujetos/objetos pesan m√°s), "
            "(3) Closeness/Betweenness = centralidad en el grafo. **QID de Wikidata** vincula entidades a la "
            "base can√≥nica. Entidades con alta frecuencia pero baja centralidad pueden ser menciones superficiales "
            "sin desarrollo profundo."
        ),
        "best_practices": (
            "**Paso 1**: Usa texto plano (no HTML) en la columna de contenido para an√°lisis limpio. **Paso 2**: "
            "Activa Entity Linking a Wikidata para vincular con el Knowledge Graph oficial. **Paso 3**: Configura "
            "tipos de entidad seg√∫n tu nicho (ORG, PRODUCT para eCommerce; PERSON, EVENT para noticias). **Paso 4**: "
            "Usa la whitelist manual para forzar la inclusi√≥n de entidades clave de tu marca/nicho (recibir√°n boost "
            "3x en prominence). **Paso 5**: Revisa entidades de alta frecuencia pero baja centralidad - necesitan "
            "m√°s contexto y relaciones. **Paso 6**: Identifica entidades ausentes comparando con competidores - son "
            "oportunidades de expansi√≥n. Ideal para content briefs, optimizaci√≥n on-page y estrategia de E-E-A-T."
        ),
    },
    "semantic_depth_score": {
        "title": "Semantic Depth Score (SDS)",
        "seo_theory": (
            "El SDS cuantifica la calidad del contenido m√°s all√° de la longitud o densidad de keywords. Combina "
            "dos dimensiones cr√≠ticas: (1) **Entity Relevance (ER)**: mide la completitud del conocimiento mediante "
            "densidad y co-ocurrencia de entidades relevantes, capitalizando el efecto Quality Smear de la patente "
            "de Google; (2) **Vector Cohesion (CV)**: mide la coherencia narrativa calculando la distancia promedio "
            "de frases al centroide sem√°ntico del documento. Google MUM y BERT eval√∫an contenido de forma similar, "
            "premiando cobertura exhaustiva de entidades (E-E-A-T) y discurso cohesivo (user experience). Un SDS "
            "alto indica contenido que satisface completamente la intenci√≥n de b√∫squeda con profundidad y enfoque."
        ),
        "interpretation": (
            "El SDS va de 0-100 con 3 rangos: **üî¥ 0-33 (Thin)**: baja densidad de entidades, dispersi√≥n alta - "
            "contenido superficial que necesita expansi√≥n profunda. **üü° 34-66 (Decente)**: fuerte en un componente "
            "pero d√©bil en otro - por ejemplo, muchas entidades pero sin cohesi√≥n narrativa, o muy enfocado pero "
            "con pocas entidades. **üü¢ 67-100 (√ìptimo)**: alta densidad de entidades relevantes + discurso cohesivo "
            "= autoridad tem√°tica. **Score ER** alto con **Score CV** bajo indica contenido disperso (menciona muchos "
            "temas sin profundizar). ER bajo con CV alto indica contenido enfocado pero superficial (falta cobertura "
            "de entidades). La **densidad de entidades** √≥ptima var√≠a por nicho: t√©cnico/educativo >0.05, comercial "
            "0.02-0.04."
        ),
        "best_practices": (
            "**Paso 1**: Analiza tu top 10 p√°ginas con mejor rendimiento para establecer tu baseline de SDS √≥ptimo. "
            "**Paso 2**: Identifica p√°ginas con SDS <50 - son candidatas prioritarias para reescritura. **Paso 3**: "
            "Para mejorar Score ER, a√±ade entidades relacionadas del Knowledge Graph (usa an√°lisis de competidores "
            "top-ranking). **Paso 4**: Para mejorar Score CV, reestructura el contenido agrupando ideas relacionadas, "
            "elimina secciones off-topic y refuerza transiciones entre p√°rrafos. **Paso 5**: Monitorea SDS despu√©s "
            "de optimizaciones - aumentos de 10+ puntos correlacionan con mejoras de ranking. **Paso 6**: Usa SDS "
            "en content briefs para writers: especifica target SDS >70 y lista entidades obligatorias. Ideal para "
            "content quality audits y optimizaci√≥n on-page estrat√©gica."
        ),
    },
    "linking_lab": {
        "title": "Laboratorio de Enlazado Interno",
        "seo_theory": (
            "El internal linking es uno de los factores de ranking m√°s controlables. Distribuye PageRank, se√±ala "
            "relevancia tem√°tica y mejora crawlability. El enlazado sem√°ntico (basado en similitud de embeddings) "
            "supera al keyword matching tradicional porque refleja c√≥mo Google entiende relaciones entre p√°ginas. "
            "El algoritmo PageRank flow muestra c√≥mo se distribuye la autoridad: p√°ginas con alto PR pero pocas "
            "outbound links son 'hoarders' (acumulan autoridad sin distribuir), p√°ginas con bajo PR pero muchos "
            "inbound son 'candidates' (receptores potenciales). El linking strategy √≥ptimo balancea: (1) enlazar "
            "contenido similar (clusters sem√°nticos), (2) distribuir autoridad de hubs a contenido long-tail, "
            "(3) crear topic clusters con pillar pages."
        ),
        "interpretation": (
            "La tabla de **sugerencias de enlaces** muestra pares Source‚ÜíTarget con: **Similitud sem√°ntica** (0-1): "
            ">0.7 = muy relacionado, 0.5-0.7 = relacionado, <0.5 = d√©bilmente relacionado. **PageRank Source/Target**: "
            "enlazar desde p√°ginas con PR alto hacia PR bajo distribuye autoridad. **Ganancia de PR**: proyecci√≥n de "
            "cu√°nto PR ganar√≠a el target si recibe el enlace. **Prioridad**: m√©trica combinada que balancea similitud, "
            "ganancia de PR y estrategia. El **an√°lisis de PageRank** muestra: p√°ginas con alto PR son tus assets "
            "(distribuye su autoridad), p√°ginas con bajo PR pero alto potencial necesitan enlaces internos, p√°ginas "
            "hu√©rfanas (sin inbound) son invisibles para bots."
        ),
        "best_practices": (
            "**Paso 1**: Carga CSV con URL, embeddings y datos de PageRank (o usa solo embeddings para an√°lisis b√°sico). "
            "**Paso 2**: Configura similitud m√≠nima ~0.6 para enlaces muy relacionados, o ~0.4 para descubrimiento m√°s "
            "amplio. **Paso 3**: Filtra por tipo de p√°gina (product‚Üíproduct, blog‚Üíblog) para consistencia. **Paso 4**: "
            "Prioriza enlaces desde p√°ginas con PR >0.01 hacia p√°ginas con PR <0.001 (flujo estrat√©gico de autoridad). "
            "**Paso 5**: Implementa 5-10 enlaces internos por p√°gina para evitar diluci√≥n. **Paso 6**: Exporta "
            "sugerencias y valida manualmente que el contexto sea relevante antes de implementar. **Paso 7**: Re-analiza "
            "despu√©s de 30 d√≠as para medir cambios en distribuci√≥n de PageRank. Ideal para rescatar contenido hu√©rfano, "
            "potenciar product pages y construir topic authority."
        ),
    },
    "positions_report": {
        "title": "Informe de Posiciones SEO",
        "seo_theory": (
            "El tracking de posiciones es fundamental para medir el impacto de optimizaciones SEO. El an√°lisis por "
            "familias de keywords permite detectar: (1) **Topic authority**: grupos de keywords rankean alto = "
            "Google reconoce tu expertise, (2) **Keyword gaps**: familias con posiciones bajas = oportunidades "
            "de optimizaci√≥n, (3) **SERP volatility**: cambios frecuentes indican competencia alta o contenido "
            "que no satisface intent. La evoluci√≥n temporal de posiciones (l√≠neas de tendencia) correlaciona con "
            "updates de algoritmo, acciones de competidores y tus optimizaciones. Keywords en posiciones 11-20 "
            "(p√°gina 2) son low-hanging fruit con m√°ximo ROI de optimizaci√≥n - peque√±as mejoras generan tr√°fico "
            "significativo."
        ),
        "interpretation": (
            "La **tabla de posiciones** muestra keyword, posici√≥n actual y dominio ranking. **Familias de keywords** "
            "agrupan t√©rminos relacionados - observa: (1) Familias con posici√≥n promedio <10 son tus fortalezas, "
            "(2) Familias con posici√≥n 11-30 son quick wins, (3) Familias >30 necesitan estrategia profunda. "
            "**Featured snippets** (posici√≥n 0) generan CTR alto con bajo traffic - optimiza para question queries. "
            "**Dominios competidores** frecuentes en top 10 son benchmarks - analiza su contenido para identificar "
            "gaps. El **gr√°fico de evoluci√≥n** muestra tendencias: subidas consistentes = optimizaciones efectivas, "
            "ca√≠das s√∫bitas = penalizaci√≥n o update de algoritmo, volatilidad = SERP inestable."
        ),
        "best_practices": (
            "**Paso 1**: Carga CSV de rank tracker (SEMrush, Ahrefs, SERPWatcher) con formato: Keyword | Position | URL. "
            "Soporta formato SERP (columnas Position 1, Position 2, etc.) o simple. **Paso 2**: Define familias de "
            "keywords usando patterns (ej: 'Familia Product: *producto*, *precio*, *comprar*'). **Paso 3**: Filtra "
            "keywords en posiciones 11-20 para identificar quick wins. **Paso 4**: Para cada familia d√©bil, cruza con "
            "an√°lisis de SDS - p√°ginas con SDS bajo necesitan content rewrite, SDS alto necesitan m√°s backlinks. "
            "**Paso 5**: Monitorea evoluci√≥n semanal - cambios >5 posiciones requieren investigaci√≥n (competidor nuevo, "
            "update, etc.). **Paso 6**: Exporta reporte con familias prioritarias para planning. Ideal para tracking "
            "de campa√±as, reporting a clientes y priorizaci√≥n de optimizaciones."
        ),
    },
    "embeddings_analysis": {
        "title": "An√°lisis de Embeddings Sem√°nticos",
        "seo_theory": (
            "Los embeddings (representaciones vectoriales de texto) son la base de c√≥mo Google entiende el lenguaje "
            "desde BERT (2019). Cada documento se convierte en un vector de alta dimensi√≥n (384-4096 dims) donde "
            "la distancia coseno refleja similitud sem√°ntica. Esto permite: (1) **Content similarity**: detectar "
            "contenido duplicado sem√°ntico (no solo textual), (2) **Topic modeling**: descubrir temas latentes, "
            "(3) **Search intent matching**: alinear contenido con queries de usuarios. La visualizaci√≥n t-SNE/UMAP "
            "reduce dimensiones para mostrar clusters naturales - documentos cercanos tienen intenci√≥n de b√∫squeda "
            "similar. Modelos SOTA (BGE-M3, NV-Embed-v2) capturan matices que TF-IDF no puede, como sin√≥nimos, "
            "contexto y relaciones sem√°nticas complejas."
        ),
        "interpretation": (
            "El **gr√°fico t-SNE** muestra tus URLs como puntos en 2D - la proximidad espacial indica similitud "
            "sem√°ntica. **Clusters densos** = grupo de URLs sobre el mismo tema (verifica si es canibalizaci√≥n o "
            "topic cluster intencional). **URLs aisladas** = contenido √∫nico sin p√°ginas relacionadas (oportunidad "
            "de expansi√≥n o contenido off-brand). **Colores** representan clusters autom√°ticos o tipos de p√°gina. "
            "La **matriz de similitud** muestra pares de URLs con similitud >umbral - valores >0.8 indican "
            "canibalizaci√≥n probable, 0.6-0.8 = contenido relacionado (buen candidato para internal linking), "
            "<0.4 = sin relaci√≥n sem√°ntica."
        ),
        "best_practices": (
            "**Paso 1**: Genera embeddings con modelos multiling√ºes (all-MiniLM-L6-v2 para velocidad, BGE-M3 para "
            "precisi√≥n, NV-Embed-v2 para m√°xima calidad). **Paso 2**: Usa texto completo (no snippets) para embeddings "
            "precisos - m√≠nimo 100 palabras por documento. **Paso 3**: Revisa clusters en t-SNE: densos requieren "
            "validaci√≥n de canibalizaci√≥n, dispersos sugieren falta de topic authority. **Paso 4**: Exporta matriz "
            "de similitud y √∫sala para: (a) internal linking strategy, (b) identificar contenido a consolidar, "
            "(c) detectar gaps tem√°ticos (√°reas sin cobertura). **Paso 5**: Combina con an√°lisis de performance: "
            "clusters con bajo tr√°fico necesitan optimizaci√≥n. Ideal para auditor√≠as de arquitectura de informaci√≥n "
            "y detecci√≥n de canibalizaci√≥n sem√°ntica."
        ),
    },
    "topic_modeling": {
        "title": "Modelado de T√≥picos (LDA/NMF)",
        "seo_theory": (
            "El topic modeling descubre autom√°ticamente temas latentes en tu contenido usando algoritmos LDA "
            "(Latent Dirichlet Allocation) o NMF (Non-negative Matrix Factorization). En SEO, esto permite: "
            "(1) **Topic coverage audit**: identificar qu√© temas cubres vs. competidores, (2) **Content gaps**: "
            "detectar subtemas ausentes en tu sitio, (3) **Topical authority**: medir profundidad de cobertura "
            "por tema. Google eval√∫a sites por topical authority - sitios que cubren un tema exhaustivamente "
            "(m√∫ltiples subtemas relacionados) rankean mejor que sitios dispersos. Cada t√≥pico se representa por "
            "keywords clave - la distribuci√≥n de t√≥picos por URL muestra si tu contenido est√° enfocado (1-2 t√≥picos "
            "dominantes) o disperso (muchos t√≥picos con peso similar)."
        ),
        "interpretation": (
            "La **tabla de t√≥picos** muestra cada tema descubierto con sus top keywords. Interpreta: (1) Keywords "
            "coherentes = t√≥pico bien definido, (2) Keywords inconexas = ruido o t√≥pico muy gen√©rico. La **distribuci√≥n "
            "de t√≥picos por URL** muestra qu√© porcentaje de cada documento pertenece a cada tema. **Documentos "
            "enfocados** tienen 1 t√≥pico dominante (>60%), **documentos dispersos** tienen m√∫ltiples t√≥picos con "
            "peso similar (<30% cada uno) - se√±al de falta de enfoque. El **gr√°fico de t√≥picos** visualiza la "
            "distancia entre temas - t√≥picos cercanos son relacionados (buenos para topic clusters), t√≥picos "
            "lejanos son independientes."
        ),
        "best_practices": (
            "**Paso 1**: Usa corpus >50 documentos para topic modeling robusto (m√≠nimo 30). **Paso 2**: Prueba "
            "diferentes n√∫meros de t√≥picos (k): empieza con k=10, ajusta seg√∫n coherencia de keywords. **Paso 3**: "
            "LDA para t√≥picos m√°s coherentes y interpretables, NMF para t√≥picos m√°s espec√≠ficos y separables. "
            "**Paso 4**: Revisa t√≥picos descubiertos: (a) t√≥picos con muchos documentos son tus pilares de contenido, "
            "(b) t√≥picos con pocos documentos son gaps de oportunidad, (c) t√≥picos inesperados revelan contenido "
            "off-brand o secundario. **Paso 5**: Crea topic clusters: agrupa URLs del mismo t√≥pico con pillar page "
            "central enlazando a subtemas. **Paso 6**: Compara tus t√≥picos vs. competidores para estrategia. Ideal "
            "para auditor√≠as de contenido, planificaci√≥n de content hubs y estrategia de topical authority."
        ),
    },
    "csv_upload": {
        "title": "Carga y Procesamiento de CSV",
        "seo_theory": (
            "La preparaci√≥n correcta de datos es fundamental para an√°lisis SEO precisos. Un CSV bien estructurado "
            "permite an√°lisis a escala que ser√≠an imposibles manualmente. Columnas esenciales: (1) **URL**: "
            "identificador √∫nico de cada p√°gina, (2) **Texto/Contenido**: contenido completo para NER y embeddings, "
            "(3) **Embeddings**: representaci√≥n vectorial pre-calculada (opcional), (4) **Metadata**: tipo de p√°gina, "
            "fecha de publicaci√≥n, autor, etc. para segmentaci√≥n. La calidad del input determina la calidad del "
            "an√°lisis - garbage in, garbage out. Datos limpios y completos permiten identificar patterns que "
            "correlacionan con performance de ranking."
        ),
        "interpretation": (
            "Despu√©s de cargar el CSV, la **vista previa** muestra las primeras filas - verifica: (1) columnas "
            "detectadas correctamente, (2) tipos de datos apropiados (URL como texto, embeddings como vectores), "
            "(3) valores faltantes (NaN). El **resumen de columnas** indica: URLs √∫nicas, valores nulos, longitud "
            "promedio de contenido. **Warnings** sobre columnas faltantes o formato incorrecto deben resolverse "
            "antes de an√°lisis. La **detecci√≥n autom√°tica** identifica columnas de URL, texto y embeddings - "
            "verifica que la asignaci√≥n sea correcta."
        ),
        "best_practices": (
            "**Paso 1**: Exporta datos desde tu herramienta SEO (Screaming Frog, SEMrush, Ahrefs) o CMS. **Paso 2**: "
            "Asegura formato UTF-8 para caracteres especiales (tildes, √±). **Paso 3**: Columna de texto: usa texto "
            "plano completo, no HTML - m√≠nimo 100 palabras para an√°lisis robusto. **Paso 4**: Si incluyes embeddings "
            "pre-calculados, usa formato array numpy o lista. **Paso 5**: A√±ade columnas de metadata √∫tiles: "
            "'tipo_pagina', 'categoria', 'autor' para an√°lisis segmentado. **Paso 6**: Elimina filas con URL "
            "duplicadas antes de cargar. **Paso 7**: Para sitios grandes (>10k URLs), segmenta el an√°lisis por "
            "secci√≥n/categoria para performance. Ideal como primer paso para cualquier an√°lisis SEO a escala."
        ),
    },
}


def get_help_content(section_key: str) -> HelpContent | None:
    """
    Obtiene el contenido de ayuda para una secci√≥n espec√≠fica.

    Args:
        section_key: Clave de la secci√≥n (ej: "clustering", "knowledge_graph")

    Returns:
        Diccionario con contenido de ayuda o None si no existe
    """
    return HELP_SECTIONS.get(section_key)


def list_available_help_sections() -> list[str]:
    """
    Lista todas las secciones con ayuda disponible.

    Returns:
        Lista de claves de secciones
    """
    return list(HELP_SECTIONS.keys())


__all__ = [
    "HELP_SECTIONS",
    "HelpContent",
    "get_help_content",
    "list_available_help_sections",
]
